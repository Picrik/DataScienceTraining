{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Objective : redo form there : https://datastud.dev/posts/nlp-preprocess\n",
    "\n",
    "Learn :\n",
    "* NLTK\n",
    "* PyTorch\n",
    "* Spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\JeremySCHNEIDER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('wordnet', quiet=True)\n",
    "\n",
    "from torchtext.data import get_tokenizer\n",
    "\n",
    "from spacy.tokenizer import Tokenizer\n",
    "from spacy.lang.en import English"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(input_text):\n",
    "    return [token for token in input_text if token.lower() not in stopwords.words('english')]\n",
    "\n",
    "def remove_punctuation(input_text):\n",
    "    return [token for token in input_text if token not in set(string.punctuation)]\n",
    "\n",
    "def lemmatize(input_text):\n",
    "    # Instantiate class\n",
    "    lem = WordNetLemmatizer()\n",
    "    # Lemmatized text becomes input inside all loop runs\n",
    "    lemmatized_text = input_text\n",
    "    # Lemmatize each part of speech\n",
    "    for part_of_speech in ['n', 'v', 'a', 'r', 's']:\n",
    "        lemmatized_text = [lem.lemmatize(token, part_of_speech).lower() for token in lemmatized_text]\n",
    "    return lemmatized_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Open files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"DATA/the_wind_cries_mary.txt\", \"r\") as f:\n",
    "    lines = f.readlines()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['After all the jacks are in their boxes\\n',\n",
       " 'And the clowns have all gone to bed\\n',\n",
       " 'You can hear happiness staggering on down the street\\n',\n",
       " 'Footprints dressed in red\\n',\n",
       " 'And the wind whispers Mary \\n',\n",
       " 'A broom is drearily sweeping\\n',\n",
       " 'Up the broken pieces of yesterdays life\\n',\n",
       " 'Somewhere a queen is weeping\\n',\n",
       " 'Somewhere a king has no wife\\n',\n",
       " 'And the wind, it cries Mary \\n',\n",
       " 'The traffic lights they all true blue tomorrow\\n',\n",
       " 'And shine their emptiness down on my bed\\n',\n",
       " 'The tiny island sags downstream\\n',\n",
       " 'Cause the life that lived is, is dead\\n',\n",
       " 'And the wind screams Mary \\n',\n",
       " 'Will the wind ever remember\\n',\n",
       " 'The names it has blown in the past\\n',\n",
       " \"And with his crutch, its old age, and it's wisdom\\n\",\n",
       " 'It whispers no, this will be the last\\n',\n",
       " 'And the wind cries Mary ']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['After', 'all', 'the', 'jacks', 'are', 'in', 'their', 'boxes'],\n",
       " ['And', 'the', 'clowns', 'have', 'all', 'gone', 'to', 'bed'],\n",
       " ['You',\n",
       "  'can',\n",
       "  'hear',\n",
       "  'happiness',\n",
       "  'staggering',\n",
       "  'on',\n",
       "  'down',\n",
       "  'the',\n",
       "  'street'],\n",
       " ['Footprints', 'dressed', 'in', 'red'],\n",
       " ['And', 'the', 'wind', 'whispers', 'Mary'],\n",
       " ['A', 'broom', 'is', 'drearily', 'sweeping'],\n",
       " ['Up', 'the', 'broken', 'pieces', 'of', 'yesterdays', 'life'],\n",
       " ['Somewhere', 'a', 'queen', 'is', 'weeping'],\n",
       " ['Somewhere', 'a', 'king', 'has', 'no', 'wife'],\n",
       " ['And', 'the', 'wind', ',', 'it', 'cries', 'Mary'],\n",
       " ['The', 'traffic', 'lights', 'they', 'all', 'true', 'blue', 'tomorrow'],\n",
       " ['And', 'shine', 'their', 'emptiness', 'down', 'on', 'my', 'bed'],\n",
       " ['The', 'tiny', 'island', 'sags', 'downstream'],\n",
       " ['Cause', 'the', 'life', 'that', 'lived', 'is', ',', 'is', 'dead'],\n",
       " ['And', 'the', 'wind', 'screams', 'Mary'],\n",
       " ['Will', 'the', 'wind', 'ever', 'remember'],\n",
       " ['The', 'names', 'it', 'has', 'blown', 'in', 'the', 'past'],\n",
       " ['And',\n",
       "  'with',\n",
       "  'his',\n",
       "  'crutch',\n",
       "  ',',\n",
       "  'its',\n",
       "  'old',\n",
       "  'age',\n",
       "  ',',\n",
       "  'and',\n",
       "  'it',\n",
       "  \"'s\",\n",
       "  'wisdom'],\n",
       " ['It', 'whispers', 'no', ',', 'this', 'will', 'be', 'the', 'last'],\n",
       " ['And', 'the', 'wind', 'cries', 'Mary']]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines_tokenized = [word_tokenize(line) for line in lines]\n",
    "lines_tokenized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "# View stopwords\n",
    "print(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['jacks', 'boxes'],\n",
       " ['clowns', 'gone', 'bed'],\n",
       " ['hear', 'happiness', 'staggering', 'street'],\n",
       " ['Footprints', 'dressed', 'red'],\n",
       " ['wind', 'whispers', 'Mary'],\n",
       " ['broom', 'drearily', 'sweeping'],\n",
       " ['broken', 'pieces', 'yesterdays', 'life'],\n",
       " ['Somewhere', 'queen', 'weeping'],\n",
       " ['Somewhere', 'king', 'wife'],\n",
       " ['wind', ',', 'cries', 'Mary'],\n",
       " ['traffic', 'lights', 'true', 'blue', 'tomorrow'],\n",
       " ['shine', 'emptiness', 'bed'],\n",
       " ['tiny', 'island', 'sags', 'downstream'],\n",
       " ['Cause', 'life', 'lived', ',', 'dead'],\n",
       " ['wind', 'screams', 'Mary'],\n",
       " ['wind', 'ever', 'remember'],\n",
       " ['names', 'blown', 'past'],\n",
       " ['crutch', ',', 'old', 'age', ',', \"'s\", 'wisdom'],\n",
       " ['whispers', ',', 'last'],\n",
       " ['wind', 'cries', 'Mary']]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply stopword function\n",
    "tokens_without_stopwords = [remove_stopwords(line) for line in lines_tokenized]\n",
    "tokens_without_stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['jacks', 'boxes'],\n",
       " ['clowns', 'gone', 'bed'],\n",
       " ['hear', 'happiness', 'staggering', 'street'],\n",
       " ['Footprints', 'dressed', 'red'],\n",
       " ['wind', 'whispers', 'Mary'],\n",
       " ['broom', 'drearily', 'sweeping'],\n",
       " ['broken', 'pieces', 'yesterdays', 'life'],\n",
       " ['Somewhere', 'queen', 'weeping'],\n",
       " ['Somewhere', 'king', 'wife'],\n",
       " ['wind', 'cries', 'Mary'],\n",
       " ['traffic', 'lights', 'true', 'blue', 'tomorrow'],\n",
       " ['shine', 'emptiness', 'bed'],\n",
       " ['tiny', 'island', 'sags', 'downstream'],\n",
       " ['Cause', 'life', 'lived', 'dead'],\n",
       " ['wind', 'screams', 'Mary'],\n",
       " ['wind', 'ever', 'remember'],\n",
       " ['names', 'blown', 'past'],\n",
       " ['crutch', 'old', 'age', \"'s\", 'wisdom'],\n",
       " ['whispers', 'last'],\n",
       " ['wind', 'cries', 'Mary']]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply punctuation function\n",
    "tokens_without_punctuation = [remove_punctuation(line) for line in tokens_without_stopwords]\n",
    "tokens_without_punctuation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cry'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lem = WordNetLemmatizer()\n",
    "lem.lemmatize('cries')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['jack', 'box'],\n",
       " ['clown', 'go', 'bed'],\n",
       " ['hear', 'happiness', 'stagger', 'street'],\n",
       " ['footprints', 'dress', 'red'],\n",
       " ['wind', 'whisper', 'mary'],\n",
       " ['broom', 'drearily', 'sweep'],\n",
       " ['break', 'piece', 'yesterday', 'life'],\n",
       " ['somewhere', 'queen', 'weep'],\n",
       " ['somewhere', 'king', 'wife'],\n",
       " ['wind', 'cry', 'mary'],\n",
       " ['traffic', 'light', 'true', 'blue', 'tomorrow'],\n",
       " ['shine', 'emptiness', 'bed'],\n",
       " ['tiny', 'island', 'sag', 'downstream'],\n",
       " ['cause', 'life', 'live', 'dead'],\n",
       " ['wind', 'scream', 'mary'],\n",
       " ['wind', 'ever', 'remember'],\n",
       " ['name', 'blow', 'past'],\n",
       " ['crutch', 'old', 'age', \"'s\", 'wisdom'],\n",
       " ['whisper', 'last'],\n",
       " ['wind', 'cry', 'mary']]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply lemmatize function\n",
    "tokens_lemmatized = [lemmatize(line) for line in tokens_without_punctuation]\n",
    "tokens_lemmatized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['after', 'all', 'the', 'jacks', 'are', 'in', 'their', 'boxes'],\n",
       " ['and', 'the', 'clowns', 'have', 'all', 'gone', 'to', 'bed'],\n",
       " ['you',\n",
       "  'can',\n",
       "  'hear',\n",
       "  'happiness',\n",
       "  'staggering',\n",
       "  'on',\n",
       "  'down',\n",
       "  'the',\n",
       "  'street'],\n",
       " ['footprints', 'dressed', 'in', 'red'],\n",
       " ['and', 'the', 'wind', 'whispers', 'mary'],\n",
       " ['a', 'broom', 'is', 'drearily', 'sweeping'],\n",
       " ['up', 'the', 'broken', 'pieces', 'of', 'yesterdays', 'life'],\n",
       " ['somewhere', 'a', 'queen', 'is', 'weeping'],\n",
       " ['somewhere', 'a', 'king', 'has', 'no', 'wife'],\n",
       " ['and', 'the', 'wind', ',', 'it', 'cries', 'mary'],\n",
       " ['the', 'traffic', 'lights', 'they', 'all', 'true', 'blue', 'tomorrow'],\n",
       " ['and', 'shine', 'their', 'emptiness', 'down', 'on', 'my', 'bed'],\n",
       " ['the', 'tiny', 'island', 'sags', 'downstream'],\n",
       " ['cause', 'the', 'life', 'that', 'lived', 'is', ',', 'is', 'dead'],\n",
       " ['and', 'the', 'wind', 'screams', 'mary'],\n",
       " ['will', 'the', 'wind', 'ever', 'remember'],\n",
       " ['the', 'names', 'it', 'has', 'blown', 'in', 'the', 'past'],\n",
       " ['and',\n",
       "  'with',\n",
       "  'his',\n",
       "  'crutch',\n",
       "  ',',\n",
       "  'its',\n",
       "  'old',\n",
       "  'age',\n",
       "  ',',\n",
       "  'and',\n",
       "  'it',\n",
       "  \"'\",\n",
       "  's',\n",
       "  'wisdom'],\n",
       " ['it', 'whispers', 'no', ',', 'this', 'will', 'be', 'the', 'last'],\n",
       " ['and', 'the', 'wind', 'cries', 'mary']]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pytorch_tokenizer = get_tokenizer(\"basic_english\")\n",
    "pytorch_tokens = [pytorch_tokenizer(line) for line in lines]\n",
    "pytorch_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[After all the jacks are in their boxes,\n",
       " And the clowns have all gone to bed,\n",
       " You can hear happiness staggering on down the street,\n",
       " Footprints dressed in red,\n",
       " And the wind whispers Mary ,\n",
       " A broom is drearily sweeping,\n",
       " Up the broken pieces of yesterdays life,\n",
       " Somewhere a queen is weeping,\n",
       " Somewhere a king has no wife,\n",
       " And the wind, it cries Mary ,\n",
       " The traffic lights they all true blue tomorrow,\n",
       " And shine their emptiness down on my bed,\n",
       " The tiny island sags downstream,\n",
       " Cause the life that lived is, is dead,\n",
       " And the wind screams Mary ,\n",
       " Will the wind ever remember,\n",
       " The names it has blown in the past,\n",
       " And with his crutch, its old age, and it's wisdom,\n",
       " It whispers no, this will be the last,\n",
       " And the wind cries Mary ]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp = English()\n",
    "spacy_tokenizer = Tokenizer(nlp.vocab)\n",
    "spacy_tokens = [spacy_tokenizer(line) for line in lines]\n",
    "spacy_tokens # spacy return a doc object, not just list of words. See more here: https://spacy.io/api/doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['After', 'all', 'the', 'jacks', 'are', 'in', 'their', 'boxes', '\\n'],\n",
       " ['And', 'the', 'clowns', 'have', 'all', 'gone', 'to', 'bed', '\\n'],\n",
       " ['You',\n",
       "  'can',\n",
       "  'hear',\n",
       "  'happiness',\n",
       "  'staggering',\n",
       "  'on',\n",
       "  'down',\n",
       "  'the',\n",
       "  'street',\n",
       "  '\\n'],\n",
       " ['Footprints', 'dressed', 'in', 'red', '\\n'],\n",
       " ['And', 'the', 'wind', 'whispers', 'Mary', '\\n'],\n",
       " ['A', 'broom', 'is', 'drearily', 'sweeping', '\\n'],\n",
       " ['Up', 'the', 'broken', 'pieces', 'of', 'yesterdays', 'life', '\\n'],\n",
       " ['Somewhere', 'a', 'queen', 'is', 'weeping', '\\n'],\n",
       " ['Somewhere', 'a', 'king', 'has', 'no', 'wife', '\\n'],\n",
       " ['And', 'the', 'wind,', 'it', 'cries', 'Mary', '\\n'],\n",
       " ['The', 'traffic', 'lights', 'they', 'all', 'true', 'blue', 'tomorrow', '\\n'],\n",
       " ['And', 'shine', 'their', 'emptiness', 'down', 'on', 'my', 'bed', '\\n'],\n",
       " ['The', 'tiny', 'island', 'sags', 'downstream', '\\n'],\n",
       " ['Cause', 'the', 'life', 'that', 'lived', 'is,', 'is', 'dead', '\\n'],\n",
       " ['And', 'the', 'wind', 'screams', 'Mary', '\\n'],\n",
       " ['Will', 'the', 'wind', 'ever', 'remember', '\\n'],\n",
       " ['The', 'names', 'it', 'has', 'blown', 'in', 'the', 'past', '\\n'],\n",
       " ['And',\n",
       "  'with',\n",
       "  'his',\n",
       "  'crutch,',\n",
       "  'its',\n",
       "  'old',\n",
       "  'age,',\n",
       "  'and',\n",
       "  \"it's\",\n",
       "  'wisdom',\n",
       "  '\\n'],\n",
       " ['It', 'whispers', 'no,', 'this', 'will', 'be', 'the', 'last', '\\n'],\n",
       " ['And', 'the', 'wind', 'cries', 'Mary']]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[[token.text for token in line] for line in spacy_tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
